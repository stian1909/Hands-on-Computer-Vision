{"cells":[{"cell_type":"markdown","metadata":{},"source":["<img src=\"https://raw.githubusercontent.com/semilleroCV/Hands-on-Computer-Vision/main/Sesiones/Sesion6/Parte-2/imagenes/Banner%20Hands-on.png\" width=\"1600\" align=\"middle\"/>"]},{"cell_type":"markdown","metadata":{},"source":["# <font color='#ECA702'>**Hands-on Sesión 6: Time of flight**</font>"]},{"cell_type":"markdown","metadata":{},"source":["\n","El \"Time of Flight\" (ToF) es una técnica de medición que determina la distancia entre un sensor y un objeto al calcular el tiempo que tarda una señal emitida, como un pulso de luz o una onda de sonido, en viajar desde el sensor hasta el objeto y regresar. Esta tecnología se utiliza ampliamente en varias aplicaciones, incluyendo la medición de distancias, la creación de imágenes 3D, y en sensores para robótica y vehículos autónomos.\n","\n","<table style=\"width:100%; table-layout:fixed;\">\n","  <tr>\n","    <td style=\"text-align:center;\">\n","      <img src=\"https://raw.githubusercontent.com/semilleroCV/Hands-on-Computer-Vision/main/Sesiones/Sesion6/Parte-2/imagenes/app1.jpg\" width=\"800px\"/>\n","    </td>\n","    <td style=\"text-align:center;\">\n","      <img src=\"https://raw.githubusercontent.com/semilleroCV/Hands-on-Computer-Vision/main/Sesiones/Sesion6/Parte-2/imagenes/app2.jpg\" width=\"800px\"/>\n","    </td>\n","  </tr>\n","</table>\n","\n","\n","Para esta sesión, trabajaremos con dos tipos de tecnología Time of Flight, cada uno con sus características y aplicaciones específicas:\n","\n","- Indirect Time of Flight (iToF)\n","- Direct Time of Flight (dToF)\n","\n","<div style=\"text-align: center;\">\n","    <img src=\"https://raw.githubusercontent.com/semilleroCV/Hands-on-Computer-Vision/main/Sesiones/Sesion6/Parte-2/imagenes/difference.jpg\" width=\"900\" style=\"display: block; margin: auto;\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["# <font color='#4C5FDA'>**Indirect Time of flight (iToF)**</font>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","El método \"Indirect Time of Flight\" (iToF) es una técnica utilizada en la medición de distancias y en la generación de imágenes 3D. Este método se basa en la medición del tiempo que tarda la luz en viajar desde una fuente, rebotar en un objeto y volver al sensor. \n","\n","En el iToF, la luz, generalmente un haz láser o LED, es modulada con una frecuencia específica antes de ser emitida. Cuando esta luz modulada incide en un objeto y regresa, la señal recibida tendrá un cambio de fase respecto a la señal original emitida. Midiendo este cambio de fase, el sistema puede calcular la distancia al objeto porque el cambio de fase es proporcional al doble de la distancia recorrida por la luz, dado que la luz viaja hacia el objeto y luego regresa.\n","\n","<div style=\"text-align: center;\">\n","    <img src=\"https://raw.githubusercontent.com/semilleroCV/Hands-on-Computer-Vision/main/Sesiones/Sesion6/Parte-2/imagenes/itof_image.png\" width=\"700\" style=\"display: block; margin: auto;\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["# <font color='#4C5FDA'>**Objetivo**</font>"]},{"cell_type":"markdown","metadata":{},"source":["A continuación realizaremos una simulación de un enfoque de medicion de tiempo de vuelo indirecto llamado método de cuadratura. \n","\n","\n","El método de cuadratura en el contexto de la estimación de Time of Flight (ToF) indirecto se refiere a un enfoque utilizado para medir la fase de la señal de luz reflejada en comparación con la señal de luz emitida. Este método es una parte crucial del proceso para determinar la distancia basada en la medición de fase, especialmente en sistemas que utilizan la técnica Indirect Time of Flight (iToF)."]},{"cell_type":"markdown","metadata":{},"source":["# <font color='#4C5FDA'>**Instalamos paquetes y librerias**</font>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":271,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21659,"status":"ok","timestamp":1712955056181,"user":{"displayName":"Cristian Rey","userId":"08275654324535748335"},"user_tz":300},"id":"QLk1o96mHaiM","outputId":"008b667d-56b8-4426-ef91-50296d7d7cab"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2 as cv\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":165,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1303,"status":"ok","timestamp":1712955082180,"user":{"displayName":"Cristian Rey","userId":"08275654324535748335"},"user_tz":300},"id":"W0-rImd5HaOk","outputId":"704978a8-24db-4b12-8c4b-8054b12cd69c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/cristianr/anaconda3/lib/python3.11/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1x4_o-lhGfki9uF6MTTv7JbKszOlfItrg\n","To: /home/cristianr/Sesion6/sample_1.png\n","100%|██████████████████████████████████████| 1.13M/1.13M [00:00<00:00, 14.6MB/s]\n","/home/cristianr/anaconda3/lib/python3.11/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=16ifriwMVlm6yJC2Wbfm_TDHT8wEeu36x\n","To: /home/cristianr/Sesion6/sample_3.png\n","100%|████████████████████████████████████████| 644k/644k [00:00<00:00, 2.48MB/s]\n","/home/cristianr/anaconda3/lib/python3.11/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1ufDQ6aJe3bZf9L5zA2aL-yFbFEYPXem3\n","To: /home/cristianr/Sesion6/sample_2.png\n","100%|████████████████████████████████████████| 625k/625k [00:00<00:00, 2.09MB/s]\n"]}],"source":["# Importamos datos a usar\n","\n","!gdown --id \"1x4_o-lhGfki9uF6MTTv7JbKszOlfItrg\"\n","!gdown --id \"16ifriwMVlm6yJC2Wbfm_TDHT8wEeu36x\"\n","!gdown --id \"1ufDQ6aJe3bZf9L5zA2aL-yFbFEYPXem3\""]},{"cell_type":"markdown","metadata":{},"source":["# **<font color='#ECA702'>Reto #1</font>**\n"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 1: Simulación de la Señal Reflejada</font>**\n"]},{"cell_type":"markdown","metadata":{},"source":["Primero, se establecen los parámetros básicos y las ecuaciones necesarias:\n","\n","- **Frecuencia de Modulación (f):** Se define la frecuencia de la luz modulada, típicamente en MegaHertz (MHz).\n","- **Longitud de Onda (λ):** La longitud de onda se calcula a partir de la velocidad de la luz (c) y la frecuencia: $\\lambda = \\frac{c}{f}$\n","- **Profundidad Máxima (max_depth):** Esto se refiere al rango máximo de medición, que también depende de la frecuencia de modulación y la velocidad de la luz: $\\max\\_depth = \\frac{\\lambda}{2}$\n","- **Amplitud (A):** Este es un parámetro que define la intensidad de la señal de salida.\n"]},{"cell_type":"markdown","metadata":{},"source":["1. Cálculo de la Fase: \n","\n","\\begin{align}\n","\\text{phase} &= \\frac{2 \\cdot d}{\\lambda} \\cdot 2 \\pi \\tag{1}\n","\\end{align}\n","\n","donde $d$ es la distancia medida desde el sensor al objeto.\n","\n","2. Derivación de la Distancia:\n","\n","\\begin{align}\n","\\text{d} &= \\frac{c}{2} \\cdot \\frac{\\theta}{2 \\pi f} \\tag{2} \\\\\n","\\text{d} &= \\frac{c}{2} \\cdot \\frac{\\theta}{2 \\pi} \\cdot \\frac{\\lambda}{c} \\tag{3}\n","\\end{align}"]},{"cell_type":"markdown","metadata":{},"source":["Con esto ya podremos calcular la fase para cada pixel en la imagen a partir de la profundidad con la ecuación (1). En la simulación se define la `frecuencia` en MegaHertz y con esta se pueden encontrar los valores de `wavelength`, `max_depth`, además definimos la amplitud `A`"]},{"cell_type":"code","execution_count":277,"metadata":{"id":"FKpfkoJy1xaT"},"outputs":[],"source":["\n","freq = 15 * 1e6 # en MHz\n","\n","c = 3e8 # en m/s\n","wavelength = None / None # en m\n","max_depth = None / 2 \n","\n","A = 0.5\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":2662,"status":"ok","timestamp":1712955549324,"user":{"displayName":"Cristian Rey","userId":"08275654324535748335"},"user_tz":300},"id":"fTiLwfnYx5P3","outputId":"f9702802-3e67-4e11-8b8e-4d38d904da0b"},"outputs":[],"source":["# Cargamos la imagen\n","depth_img = cv.imread(\"\") # Ruta al archivo .png\n","depth_img = np.mean(depth_img, 2)\n","\n","min_depth = np.min(depth_img)\n","max_depth = np.max(depth_img)\n","\n","depth_img = (depth_img - min_depth) / (max_depth - min_depth) + 2\n","\n","(nr, nc) = depth_img.shape\n","\n","fase_img = (2 * None / None) * 2 * np.pi\n","\n","plt.imshow(fase_img)\n","plt.colorbar()\n","\n","print(np.min(fase_img), np.max(fase_img))"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 2: Cálculo de Componentes en Cuadratura y Aplicación del Arcotangente</font>**\n"]},{"cell_type":"markdown","metadata":{},"source":["Una vez obtenida la matriz de fases, podremos calcular los cuatro términos de cuadratura. Los compnentes representan la señal sinosoidal en diferentes desfases:\n","\n","- $g_{0} = 0$\n","- $g_{1} = \\frac{\\pi}{2}$\n","- $g_{2} = \\pi$\n","- $g_{3} = \\frac{2 \\pi}{3}$\n","\n","Esto se convierte en la funcion sinosoidal desplazada, evaluada en el desfase\n","\n","$$g_{0} = \\cos(θ),g_2 = - sin(θ),g_3 = -\\cos(θ),g_4 = sin(θ)$$\n"]},{"cell_type":"markdown","metadata":{},"source":["Posteriormente utiizamos la función `arctan2` para calcular la fase de la señal combinada:\n","\n","$$\n","\\begin{align*}\n","\\text{phase\\_estimated} = \\text{arctan2}\\left(\\frac{g_{3} - g_{1}}{g_{0} - g_{2}}\\right)\n","\\end{align*}\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"executionInfo":{"elapsed":13228,"status":"ok","timestamp":1712955566748,"user":{"displayName":"Cristian Rey","userId":"08275654324535748335"},"user_tz":300},"id":"sZX_pTBzHgVj","outputId":"0acc39a0-8981-4acd-e84a-57f7868ef85f"},"outputs":[],"source":["g0 = A / 2 * None\n","g1 = - A / 2 * None\n","g2 = - A / 2 * None\n","g3 = A / 2 * None\n","\n","fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n","axs[0, 0].imshow(g0)\n","axs[0, 0].set_title('g0')\n","axs[0, 1].imshow(g1)\n","axs[0, 1].set_title('g1')\n","axs[1, 0].imshow(g2)\n","axs[1, 0].set_title('g2')\n","axs[1, 1].imshow(g3)\n","axs[1, 1].set_title('g3')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1712955575446,"user":{"displayName":"Cristian Rey","userId":"08275654324535748335"},"user_tz":300},"id":"ZZ5WEzBnHjBE","outputId":"980990e6-55e4-4aec-8535-d089d3a66753"},"outputs":[],"source":["fases = np.arctan2(None - None, None - None)\n","print(np.min(fases), np.max(fases))"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 3: Estimar la profundidad</font>**\n","\n","Con la fase estimada calculada, convertimos esta fase nuevamente a profundidad usando la ecuación (2)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":2059,"status":"ok","timestamp":1712955578112,"user":{"displayName":"Cristian Rey","userId":"08275654324535748335"},"user_tz":300},"id":"KeD_G3ucHkhM","outputId":"0aa0f07d-2dfd-43b8-de8d-2de607a60532"},"outputs":[],"source":["depth = (c/2) * ( None / (2 * np.pi * 3e8/(10*2) ) )\n","\n","plt.imshow(depth)\n","plt.colorbar()"]},{"cell_type":"markdown","metadata":{},"source":["A continuación estimamos el error entre la imagen real y la imagen estimada"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"elapsed":2662,"status":"ok","timestamp":1712955586903,"user":{"displayName":"Cristian Rey","userId":"08275654324535748335"},"user_tz":300},"id":"MRIXZFiBHlvT","outputId":"b2bacc9e-2a45-4bf6-c5fe-7ebb908aa708"},"outputs":[],"source":["plt.imshow(depth_img - depth)\n","plt.colorbar()\n","\n","print(np.min(depth), np.max(depth))\n","print(np.min(depth_img), np.max(depth_img))"]},{"cell_type":"markdown","metadata":{"id":"adGVWisqeNtg"},"source":["# **Direct Time of Flight**"]},{"cell_type":"markdown","metadata":{},"source":["El proceso \"direct Time of Flight\" (dToF) es una técnica utilizada para medir la distancia entre un sensor y un objeto mediante el uso de la luz. Funciona emitiendo un pulso de luz, usualmente un rayo láser, hacia un objeto y midiendo el tiempo que tarda ese pulso de luz en viajar desde el sensor hasta el objeto y volver. La distancia se calcula luego usando la velocidad de la luz y el tiempo medido.\n","\n","Este método es especialmente útil en aplicaciones como el mapeo en 3D, la robótica, y en dispositivos móviles para funciones relacionadas con la realidad aumentada y la fotografía. Además, debido a su precisión y capacidad para medir directamente la distancia sin necesidad de interpretación de imágenes, es una técnica valiosa en muchos campos tecnológicos y de investigación.\n","\n","<div style=\"text-align: center;\">\n","    <img src=\"https://raw.githubusercontent.com/semilleroCV/Hands-on-Computer-Vision/main/Sesiones/Sesion6/Parte-2/imagenes/tof_image.webp\" width=\"700\" style=\"display: block; margin: auto;\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{},"source":["# **<font color='#ECA702'>Reto #2</font>**\n"]},{"cell_type":"markdown","metadata":{},"source":["A continuacion simularemos el proceso de medición de tiempo de vuelo directo (dToF) y calcularemos la distancia usando una aproximación probabilística y generación de datos sintéticos"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 1: Configuración de Parámetros</font>**\n"]},{"cell_type":"code","execution_count":302,"metadata":{},"outputs":[],"source":["# Parámetros\n","c = 3e8  # Velocidad de la luz \n","max_depth = 100\n","min_depth = 1\n","time_bin = 1e-8\n","tiempo_observacion = 1e-6  # Tiempo de observación para capturar el pulso reflejado\n","path_to_depth_image = \"\"  # Ruta al archivo .png\n","\n","# Cargar la imagen de profundidad\n","profundidad_real = cv.imread(path_to_depth_image, cv.IMREAD_GRAYSCALE)\n","profundidad_real = (profundidad_real / profundidad_real.max()) * max_depth + min_depth"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 2: Simulación de los tiempos de llegada:</font>**\n"]},{"cell_type":"code","execution_count":304,"metadata":{},"outputs":[],"source":["# Simular tiempos de llegada basados en la profundidad\n","tiempos_llegada = 2 * None / None  # Calcula tiempo ida y vuelta\n"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 3: Realizamos una convolucion con un filtro gaussiano</font>**\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Cálculo de profundidad estimada\n","bins = np.arange(0, tiempo_observacion, time_bin)  # Bins de histograma\n","num_bins = len(bins) - 1\n","\n","profundidad_estimada = np.zeros_like(profundidad_real)\n","print(len(bins))"]},{"cell_type":"code","execution_count":306,"metadata":{},"outputs":[],"source":["def gaussian_filter1d(size,sigma):\n","    filter_range = np.linspace(-int(size/2),int(size/2),size)\n","    gaussian_filter = [1 / (sigma * np.sqrt(2*np.pi)) * np.exp(-x**2/(2*sigma**2)) for x in filter_range]\n","    return gaussian_filter\n","\n","hist = np.zeros((profundidad_real.shape[0], profundidad_real.shape[1], num_bins))\n","hist2 = np.zeros((profundidad_real.shape[0], profundidad_real.shape[1], num_bins + 1))\n","kernel = gaussian_filter1d(len(bins), 10)\n"]},{"cell_type":"code","execution_count":307,"metadata":{},"outputs":[],"source":["# Histogramas para cada pixel de la imagen\n","for i in range(profundidad_real.shape[0]):\n","    for j in range(profundidad_real.shape[1]):\n","        hist_vals, _ = np.histogram(tiempos_llegada[i, j], bins=bins)\n","        hist[i, j, :] = hist_vals.flatten()\n","        aux = np.convolve(hist[i, j, :], kernel, 'same')\n","        hist2[i, j, :] = aux / aux.max()"]},{"cell_type":"code","execution_count":308,"metadata":{},"outputs":[],"source":["hist2 = hist2 + np.random.normal(0, 1, hist2.shape)  # Agregando ruido gaussiano\n"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 4: Estimar la profundidad para cada píxel</font>**\n","\n","- Encontrar el 'bin' del histograma con la mayor cantidad de conteos.\n","- Determinar el tiempo de centroide (tiempo promedio) basándose en el 'bin' más poblado.\n","- Calcular la profundidad estimada a partir de este tiempo y la velocidad de la luz."]},{"cell_type":"code","execution_count":309,"metadata":{},"outputs":[],"source":["profundidad_estimada = np.zeros_like(profundidad_real)\n","\n","for i in range(profundidad_real.shape[0]):\n","    for j in range(profundidad_real.shape[1]):\n","        bin_max = np.argmax(hist2[i, j, :])\n","        tiempo_centroide = (bins[bin_max] + bins[bin_max]) / 2\n","        profundidad_estimada[i, j] = None * None / 2 \n"]},{"cell_type":"markdown","metadata":{},"source":["**<font color='#ECA702'>Paso 5: Graficar la profundidad estimada</font>**\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Visualización de resultados\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.imshow(profundidad_real, cmap='viridis')\n","plt.colorbar()\n","plt.title('Profundidad Real')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(profundidad_estimada, cmap='viridis')\n","plt.colorbar()\n","plt.title('Profundidad Estimada')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["error = np.zeros_like(profundidad_real)  # Para guardar el error\n","abs_error = np.zeros_like(profundidad_real) # Para guardar el error absoluto\n","\n","# Calcular el error\n","error = profundidad_real - profundidad_estimada\n","# Calcular el error absoluto\n","abs_error = abs(error)\n","\n","print(f\"Average error: {np.mean(abs_error)}\")\n","print(f\"Maximum absolute error: {np.max(abs_error)}\")\n","print(f\"Minimum absolute error: {np.min(abs_error)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.imshow(abs_error, vmin=0, vmax=40)\n","plt.colorbar()\n","\n","\"\"\" print(np.min(depth), np.max(depth))\n","print(np.min(depth_img), np.max(depth_img)) \"\"\""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPkrRcDXGF9NH9DqySK5FPm","mount_file_id":"13Rc0dWMZn3wsVYy4ZcWoQRw6i5RZll7X","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
