{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXoUhQWe9F"
      },
      "source": [
        "## **Contenido**\n",
        "\n",
        "[**1. Perceptron multi-capa**](#tema1)\n",
        "\n",
        "[**2. Perceptron multi-capa en pytorch**](#tema2)\n",
        "\n",
        "[**3. Redes Neuronales Convolucionales**](#tema3)\n",
        "\n",
        "\n",
        "[**4. Preguntas**](#tema7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6al02g_-W5bP"
      },
      "source": [
        "## <font color='#4C5FDA'>**Segmentación de imagenes vasculares de la retina** </font> <a name=\"tema1\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Vrl-waoLBe",
        "outputId": "c326452d-d940-4feb-b32e-50abc6f2326e"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "XGiZXY0AvczJ",
        "outputId": "44dbfda8-7890-4fe0-cc89-202af27865af"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3E0tGxRt_EC"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyvjBxe4pJIE"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zsBNm1znnu3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "import torchvision.transforms.v2 as transforms\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQAgM9hcoCDH"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d abdallahwagih/retina-blood-vessel\n",
        "! unzip retina-blood-vessel.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZTp89X6Pq-Mm",
        "outputId": "ee18a81c-efb7-40aa-c75c-fbb66279a310"
      },
      "outputs": [],
      "source": [
        "train_img_paths = sorted(glob('/content/Data/train/image/*.png'))\n",
        "train_mask_paths = sorted(glob('/content/Data/train/mask/*.png'))\n",
        "train_df = pd.DataFrame({\"images\":train_img_paths,\"masks\":train_mask_paths})\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5UPWmTlnsIGL",
        "outputId": "965e172f-6d05-4630-e7dd-f600639e778b"
      },
      "outputs": [],
      "source": [
        "test_img_paths = sorted(glob('/content/Data/test/image/*.png'))\n",
        "test_mask_paths = sorted(glob('/content/Data/test/mask/*.png'))\n",
        "test_df = pd.DataFrame({\"images\":test_img_paths,\"masks\":test_mask_paths})\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "kw7wtyYYxWsb",
        "outputId": "fd4188c5-01da-4c80-f676-84c66b2e6962"
      },
      "outputs": [],
      "source": [
        "show_imgs = 8\n",
        "idx = np.random.choice(len(train_df), show_imgs, replace=False)\n",
        "fig, axes = plt.subplots(show_imgs*2//4, 4, figsize=(10, 8))\n",
        "axes = axes.flatten()\n",
        "for i, ax in enumerate(axes):\n",
        "    new_i = i//2\n",
        "    if i % 2 ==0 :\n",
        "        full_path = train_df.loc[idx[new_i]]['images']\n",
        "        basename = os.path.basename(full_path)\n",
        "    else:\n",
        "        full_path = train_df.loc[idx[new_i]]['masks']\n",
        "        basename = os.path.basename(full_path) + ' -mask'\n",
        "    ax.imshow(plt.imread(full_path))\n",
        "    ax.set_title(basename)\n",
        "    ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Syc2aVo_xzq6"
      },
      "outputs": [],
      "source": [
        "### Elige trasnformaciones para hacer data augmentation\n",
        "### Puedes encontrar informacion acerca de las transformaciones disponibles en https://albumentations.ai/docs/api_reference/augmentations/\n",
        "train_transforms = A.Compose([\n",
        "\n",
        "])\n",
        "\n",
        "test_transforms = A.Compose([\n",
        "\n",
        "])\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, transforms_=None):\n",
        "        self.df = dataframe\n",
        "        self.transforms_ = transforms_\n",
        "        self.resize = [256, 256]\n",
        "        self.class_size = 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = cv2.cvtColor(cv2.imread(self.df.iloc[index]['images']), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.df.iloc[index]['masks'],cv2.IMREAD_GRAYSCALE)\n",
        "        mask = np.where(mask<127, 0, 1).astype(np.int16)\n",
        "        aug = self.transforms_(image=img, mask=mask)\n",
        "        img, mask = aug['image'], aug['mask']\n",
        "        img = img/255\n",
        "\n",
        "        img = torch.tensor(img, dtype=torch.float).permute(2, 0, 1)\n",
        "        target = torch.tensor(mask, dtype=torch.long)\n",
        "        sample = {'image': img, 'mask': target}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHt1YX71z7Q9",
        "outputId": "3b02c3ba-5c2c-405a-a373-022b547b3752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len train: 80\n",
            "len val: 20\n"
          ]
        }
      ],
      "source": [
        "train_dataset = #Invoca la clase MyDataset declarada para el dataset de entrenamiento\n",
        "val_dataset = #Invoca la clase MyDataset declarada para el dataset de validacion\n",
        "\n",
        "BATCH_SIZE = None\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4)\n",
        "print(f'len train: {len(train_df)}')\n",
        "print(f'len val: {len(test_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg3Sp9YJ0L5z"
      },
      "outputs": [],
      "source": [
        "class DoubleConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "     super().__init__()\n",
        "     self.double_conv = nn.Sequential(\n",
        "         #Declara las capas necesarias para realizar la doble convolución descrita en el diagrama de la UNet\n",
        "     )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Downscaling(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.maxpool_conv = ##Añade el max pooling al bloque de doble convolución\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Upscaling(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "    super().__init__()\n",
        "\n",
        "    ## Declara las capas necesarias para aumentar la escala de los mapas de caracteristicas\n",
        "    ## Puedes emplear interpolación o convolución transpuesta para lograrlo\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "      x1 = self.up(x1)\n",
        "      # input is CHW\n",
        "      diffY = x2.size()[2] - x1.size()[2]\n",
        "      diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "      x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                      diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "      x = torch.cat([x2, x1], dim=1)\n",
        "      return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv = #declara la capa de salida segun las clases de tu dataset\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZLBUIfE0N5J"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "    super().__init__()\n",
        "\n",
        "    self.n_channels = None\n",
        "    self.n_classes = None\n",
        "    self.bilinear = None\n",
        "\n",
        "    ## Siguiendo la estructura de la Unet, crea el modelo con los bloques declarados arriba\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    ## Crea el forward de la UNet, no olvides las conexiones residuales\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQHY5nZK0XVS",
        "outputId": "ee0ed57b-b584-4f4d-d768-ec5a1e5e851a"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = UNet(n_channels=3, n_classes=1)\n",
        "\n",
        "model.to(device)\n",
        "criterion = smp.losses.DiceLoss(mode=\"binary\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)\n",
        "epochs = None\n",
        "\n",
        "for epoch in range(epochs+1):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  epoch_iou_score = 0\n",
        "  train_iters = 0\n",
        "\n",
        "  for _, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch}/{epochs}')):\n",
        "\n",
        "    images, true_mask = batch['image'].to(device), batch['mask'].to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred_masks = model(images)\n",
        "    pred = pred_masks.squeeze(dim=1)\n",
        "\n",
        "    loss = criterion(pred, true_mask)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    true_mask = true_mask.round().long()\n",
        "    tp, fp, fn, tn = smp.metrics.get_stats(pred, true_mask, mode='binary', threshold=0.5)\n",
        "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\").item()\n",
        "    epoch_iou_score += iou_score\n",
        "    train_iters += 1\n",
        "\n",
        "  print(f\"Epoch Loss: {epoch_loss/train_iters:.4f}, Dice: {loss:.4f}, IoU: {epoch_iou_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIl1ZihsD4JK"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "epoch_loss = None\n",
        "train_iters = None\n",
        "epoch_iou_score = None\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _, batch in enumerate(tqdm(val_loader, desc=f'Epoch {epoch}/{epochs}')):\n",
        "        images, true_masks = batch['image'].to(device), batch['mask'].to(device)\n",
        "\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, true_masks)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        pred = pred.squeeze(dim=1)\n",
        "        pred = torch.sigmoid(pred)\n",
        "        true_mask = true_mask.round().long()\n",
        "        tp, fp, fn, tn = smp.metrics.get_stats(pred, true_mask, mode='binary', threshold=0.5)\n",
        "        iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\").item()\n",
        "        epoch_iou_score += iou_score\n",
        "        train_iters += 1\n",
        "\n",
        "print(f\"Epoch Loss: {epoch_loss/train_iters:.4f}, Dice: {loss:.4f}, IoU: {epoch_iou_score/train_iters:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "BMWvxy0DD_kT",
        "outputId": "be0b6b93-6c05-4843-ffd9-d6b054c9dcdb"
      },
      "outputs": [],
      "source": [
        "#images, masks = next(iter(val_loader))\n",
        "images, masks = batch['image'].to(device), batch['mask'].to(device)\n",
        "with torch.no_grad():\n",
        "  model_prediction = model(images)\n",
        "\n",
        "model_prediction = torch.max(model_prediction,dim=1)[0]\n",
        "\n",
        "rows, columns = 2, 6\n",
        "num_images = 24\n",
        "fig, axs = plt.subplots(rows, columns, figsize=(15, 6))\n",
        "idx = 0\n",
        "for row in range(rows):\n",
        "    for col in range(0, 6, 3):\n",
        "      if idx >= num_images:\n",
        "          break\n",
        "\n",
        "      img = images[idx].permute(1, 2, 0)\n",
        "      mask = masks[idx].squeeze()\n",
        "      predicted_masks = model_prediction[idx]\n",
        "\n",
        "\n",
        "      axs[row, col].imshow(img.cpu())\n",
        "      axs[row, col].set_title('Input image')\n",
        "      axs[row, col].axis('off')\n",
        "\n",
        "      axs[row, col+1].imshow(mask.cpu())\n",
        "      axs[row, col+1].set_title('Target Mask')\n",
        "      axs[row, col+1].axis('off')\n",
        "\n",
        "      axs[row, col+2].imshow(predicted_masks.cpu())\n",
        "      axs[row, col+2].set_title('Predicted Mask')\n",
        "      axs[row, col+2].axis('off')\n",
        "\n",
        "      idx += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
